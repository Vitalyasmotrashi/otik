\input{commonpath}
\input{\SRCROOTPATH/commonpres}

\title{
%Кодирование. Форматы файлов.
Сжатие данных. 
Сжатие без учёта контекста. Разделимые и~неразделимые коды сжатия без учёта контекста}

% \title{Простые коды. Форматы файлов}
% \title{Сжатие данных. Сжатие без учёта контекста. Разделимые коды}


\def\UnicodeVersion{12.1}
\def\UnicodeSymCount{137\,994}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\maketitle


% \input{\ROOTPATH/pres-sections/00_ss_code.tex}

\input{\SRCROOTPATH/pres-sections/symbyte.tex}

% % \section{Модель источника}
% 
% 
% \subsection{Модель источника: $X$ неизвестен}
% \begin{frame}{\insertsubsection}
% \begin{adjustwidth}{-1.em}{-1.5em}
% 
% % \def\msg{\chi}
% \def\msg{x}
% 
% 
% \small
% \setbeamertemplate{itemize/enumerate body begin}{\small}
% \setbeamertemplate{itemize/enumerate subbody begin}{\small}
% \setlength{\leftmargini}{0em} 
% % \setlength{\leftmarginii}{0.5em} 
% \setlength{\leftmarginii}{1em} 
% 
% \setlength{\parskip}{\smallskipamount} 
% \smallskip
% 
% Оценка алфавита $A_1$ и~вероятностей %$p(a)$ 
% источника по сообщению: 
% % обороноспособность (18)
% $\msg = $\termin{«молоко»}
% % (6) $ = c_1, c_2, c_3, c_4, c_5, c_6$
% 
% \begin{enumerate}
% 
% \item $A_1$ "--- koi-8, равновероятные символы: $p =
% % p(\text{к}) = p(\text{л})  = p(\text{м})= p(\text{о}) = 
% \frac{1}{256}$, $I(\msg) = 6\cdot \log_2(256) = 48$ \rlap{(бит)}
% \smallskip
% 
% \item $A_1$ "--- русский алфавит, равновероятные: $p%(\text{к}) = \ldots 
% = \frac{1}{33}$, $I(\msg) = 6\cdot \log_2(33) \approx 30,3$ 
% \smallskip
% 
% \item $A_1$ "--- Unicode {\UnicodeVersion}, равновероятные: $p = \frac{1}{\UnicodeSymCount}, I(\msg)\approx 6\cdot 17,1  \approx 102,4$ 
% \smallskip
% 
% \item $A_1 = \{\text{к}, \text{л}, \text{м}, \text{о}\}$, равновероятные: 
% % $p(\text{к}) = \ldots = \frac{1}{4}$
% $p = \frac{1}{4}$, $I(\msg) = 6\cdot \log_2(4) = 12$ 
% \medskip
% 
% \item $A_1 = \{\text{к}, \text{л}, \text{м}, \text{о}\}$ или koi-8, неравновероятные, стац-й источник без памяти:
% %\termin{Источник без памяти} "--- предполагаем $p(c_i = a) = p(a) = const$ для~всех $i$ и~всех $a \in A_1$:
% 
% о (3) + к (1) + л (1) + м (1): \hfill $p(\text{о}) = \frac{3}{6}, \hfill p(\text{к}) = p(\text{л})  = p(\text{м})= \frac{1}{6}$
% 
% $I(\msg) = - 3\cdot \log_2(\frac{3}{6}) - \log_2(\frac{1}{6})- \log_2(\frac{1}{6})- \log_2(\frac{1}{6}) = 3\cdot \log_2(2) + 3\cdot \log_2(6)
% \approx 10,8$%
% \medskip
% 
% \item 
% $A_1 = \{\text{к}, \text{л}, \text{м}, \text{о}\}$ или koi-8, 
% % неравновероятные символы, память на 1~символ:
% марковский источник первого порядка:
% % $p(c_i=a) = p(a,c_{i-1})$:
% 
% $
% \begin{array}{@{}l|c|c|c|c|@{}}
% % c_{i-1}&p(c_i=\text{к})&p(c_i=\text{л})&p(c_i=\text{м})&p(c_i=\text{о})\\\hline
% \text{предыдущий}&p(\text{к})&p(\text{л})&p(\text{м})&p(\text{о})\\\hline
% -&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}&\frac{1}{4}\\\hline
% \text{к, л, м}&0&0&0&1\\\hline
% % \text{л}&0&0&0&1\\\hline
% % \text{м}&0&0&0&1\\\hline
% \text{о}&\frac{1}{2}&\frac{1}{2}&0&0\\\hline
% \end{array}
% $\hfill$\begin{array}{@{}c@{}}
% I(\msg) = - \log_2(\frac{1}{4}) - \log_2(1) -\\
% - \log_2(\frac{1}{2})- \log_2(1)-\\- \log_2(\frac{1}{2})- \log_2(1) =\\ = 2 + 1 + 1 = 4
% \end{array}
% $\hfill\strut
% \smallskip
% \item $A_1 = \{\text{молоко}, \text{чай}\}$, равновероятные символы: $p = \frac{1}{2}, I(\msg) = 1$ 
% \smallskip
% 
% \item $A_1 = \{\text{молоко}\}$: $p = 1, I(\msg) = 0$ 
% \end{enumerate}
% 
% % всего: 
% % о (7) + с (3) + б (2) + н (2) + п (1) + р (1) + т (1) + ь (1)
% 
% % полагаем 
% % $p(\text{о}) = \frac{7}{18}, p(\text{с}) = \frac{3}{18}, p(\text{б}) = p(\text{н}) = \frac{2}{18}, p(\text{п}) = p(\text{р}) = p(\text{т}) = p(\text{ь}) = \frac{1}{18}$
% 
% % \termin{Источник с~памятью} "--- предполагаем $p(c_i = a) = p(a, c_{i-1}, c_{i-2}, \ldots)$
% 
% % после «о»: 
% % об, ор, он, ос (3): $p(\text{с}|\text{о}) = \frac{3}{6}, p(\text{б}|\text{о}) = p(\text{р}|\text{о}) =p(\text{н}|\text{о}) =\frac{1}{6}$\\
% % $p(\text{о}|\text{о}) = p(\text{п}|\text{о}) =p(\text{т}|\text{о})=p(\text{ь}|\text{о}) =0$
% 
% % бо, бн:
% % 
% % ро:
% % 
% % но (2):
% % 
% % сп, со, ст:
% % 
% % по:
% % 
% % ть:
% 
% 
% 
% \end{adjustwidth}
% 
% % \termin{Источники данных} порождают только элементы,  \termin{физические} источники информации "--- символы или элементы.
% \end{frame}
% 
% \subsection{Задачи}
% \begin{frame}{\insertsubsection}
% \small
% 
% Оценить алфавит и~построить модели источника: а) равновероятную, б) стационарную без памяти, в) марковскую первого порядка для сообщения $x$,
% по модели оценить  $I(x)$ и~$I(y)$.
% 
% \begin{enumerate}
% 
% \item $x = \text{хрюхрюхрюмяухрюмяумяухрюмяумяу}$ (30 символов, 5~«хрю» и~5 «мяу» 0001011011); $y=\text{рюх}$.
% 
% \item $x = \text{кукукукукарекукукукарекукукарекукукукарекукукареку}$ (50~символов, 5~«ку» и~5~«кукареку» аналогично); $y=\text{кар}$.
% 
% \end{enumerate}
% 
% \end{frame}

% \section{Кодирование}



% \subsection{Формальное представление информации}
% \begin{frame}{\insertsubsection}
% % \section{Формальное представление знаний}
% % \begin{frame}{\insertsection}
% % \small
% \setlength{\parskip}{0.5\parskip}
% 
% При формальном представлении %знаний 
% каждому описываемому объекту или понятию ставится в~соответствие %некоторый
% \emph{числовой код.}
% % \\
% % Связи %между кодируемыми сущностями 
% % также представляются кодами (адресами и~указателями).
% 
% 
% % % Информация может быть двух видов: 
% % \begin{tabularx}{\linewidth}{lL}
% % Виды:&
% % \begin{itemize}
% % \item дискретная (цифровая) информация;
% % \item непрерывная (аналоговая).
% % \end{itemize}
% % \end{tabularx}
% 
% % {\terminblue
% % Виды информации: непрерывная (аналоговая) %(цифровая) 
% % \rlap{и~дискретная.}
% % 
% % }
% 
% Для формализации дискретных данных
% % Для перевода неформальных данных
% % в формальный, цифровой вид 
% % должны использоваться специальные 
% используются \termin{таблицы кодировки.}
% % сопоставляющие кодируемым сущностям их коды.
% 
% Формализация %аналогового
% непрерывного
% сигнала  "--- оцифровка.
% 
% 
% \end{frame}


% % \section{Коды и~структура данных}
% 
% \subsection{Характеристики кодов}
% \begin{frame}{\insertsubsection}
% \small
% \setbeamertemplate{itemize/enumerate body begin}{\small}
% \setbeamertemplate{itemize/enumerate subbody begin}{\small}
% \setlength{\leftmargini}{0ex} 
% 
% % Свойства кодов
% \begin{enumerate}
% % \item Перв\tikz[remember picture] \node[coordinate,yshift=0em] (n0) {};ичный 
% % и~вторичный алфавиты ($A_2 = \{0, 1\}$ "--- двоичный код) 
% 
% \item Первичный алфавит $A_1$\tikz[remember picture] \node[coordinate,yshift=0.5em] (n1) {}; 
%         
% \item Оптимальность (неизбыточность) 
% \item Избыточность (в том числе помехоустойчивость) \tikz[remember picture] \node[coordinate] (n2) {};
% 
% \item Вторичный алфавит $A_2$ ($A_2 = \{0, 1\}$ "--- двоичный код) 
% \item Однозначная декодируемость
% 
% \item Разделяемость
% "---
% код $code(x)$ любой последовательности \rlap{$x = \overline{a_1\ldots a_n}% \in A_1^+
% $}\\
% единственным образом разделим на кодовые слова
% \rlap{$c_i = code(a_i), a_i \in A_1$:}
% 
% % Возможно однозначно выделить коды отдельных символов первичного алфавита.
% \begin{enumerate}
% \item коды фиксированной ширины "--- $a, b, c \to {}$ $00$, $01$, $10$;
% \item коды с~разделителем "--- $1$, $11$, $111$ ($0$ как разделитель символов);
% \item префиксные коды (дерево) "--- $0$, $10$, $11$; %"--- ни один $c_i$ не является началом другого
% \item прочие "--- например, $11, 1110111, 11100111$.
% % \hfill\texttime{16:00}
% 
% \end{enumerate}
% \end{enumerate}
% 
% % ? собирать 2 раза, а то скобка не там
%   \begin{tikzpicture}[overlay,remember picture]
% %       \path (n2) -| node[coordinate] (n3) {} (n1);
%       \draw[thick,decorate,decoration={brace,amplitude=3pt}]
% %             (n1) -- (n3) 
%             (n1-|n2) -- (n2) 
%             node[midway, right=4pt] (text) {модель источника!};
% %         \draw[blockarrow] (text.west) --  (n0);
%   \end{tikzpicture}
% 
% 
% 
% \end{frame}
% 
% % \subsection{Разделимые коды}
% % \begin{frame}{\insertsubsection}
% % % Любая последовательность
% % % кодовых слов 
% % % единственным образом разделима на кодовые слова
% % Код любой последовательности $x \in A_1^+$
% % единственным образом разделим на кодовые слова
% % $c_i = code(a_i), a_i \in A_1$
% % 
% % % Возможно однозначно выделить коды отдельных символов первичного алфавита.
% % \begin{enumerate}
% % \item Коды фиксированной ширины
% % \item Префиксные коды (дерево)
% % \item Коды с~разделителем
% % \item Прочие
% % \end{enumerate}
% % \end{frame}
% 
% \subsection{Задачи}
% \begin{frame}{\insertsubsection}
% 
% Построить разделимые коды
% % $\{a, b, c\} \to \{0, 1\}$:
% для $A_1=\{a, b, c, d, e\}$,  $A_2=\{0, 1\}$:
% 
% \begin{itemize}
% \item фиксированной ширины;
% \item префиксный;
% % \item «суффиксный»;
% \item «постфиксный»;
% \item с~разделителем;
% \item не относящийся ни к~одной категории.
% \end{itemize}
% 
% \end{frame}
% 
% 
% % % \subsection{Неравенство Крафта"--~Макмиллана}
% % \subsection{Неравенство Крафта--Макмиллана}
% % % http://www.codingtheory.nsu.ru/seminars/seminar%2010.pdf
% % \begin{frame}{\insertsubsection}
% % Пусть $L = {\ell_{1},\ldots,\ell_{k}}$ "---
% % множество длин кодовых слов.
% % $$\sum _{i=1}^{k}q^{-\ell_{i}}\leqslant 1$$
% % "--- необходимо и достаточно  для существования
% % $q$-значных префиксного и~разделимого кодов с заданным набором длин~$L$.
% % 
% % \end{frame}
% 
% \input{\ROOTPATH/pres-sections/00_code_header.tex}



% !!! До этого места — первая лекция !!!


% \section{Понятие сжатия}

\subsection{Сжатие}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-1.em}{-1.5em}
\small
\setlength{\leftmargini}{0em} 
\setlength{\parskip}{0.2\parskip} 

% Сжатие "--- удаление избыточности:
% $|code(X)|\to I(X)$ \mbox{(согласно~первой теореме Шеннона $|code(X)|\geqslant I(X)$).}

\termin{Сжатие} (компрессия, упаковка) "--- кодирование
$|code(X)| < |X|$, \mbox{причём $X$~однозначно} и~полностью восстанавливается по $code(X)$.

Согласно~первой теореме Шеннона $|code(X)|\geqslant I(X)$ (средние!).

Кодирование с~$|code(X)|\to I(X)$ и~$|code(x)|\to I(x)$ "--- \termin{оптимальное.}


\begin{enumerate}
\item \textterminblue{Сжимается не отдельное сообщение $x$, а~источник $X$.}
% \item Необходимо знать не только отдельное сообщение $x$, но и~его источник $X$.

\item Сжатие возможно только при наличии избыточности в~изначальном кодировании $X$ ($|X|>I(X)$).

\end{enumerate}

% Пусть $x$ "--- строка из $n$ октетов: $x = \chi_0, \ldots, \chi_{n-1}$;
% \mbox{источник~$X$ неизвестен.}
% 
% Если $X$ равновероятный (порождает каждую из~$N = 2^{8n}$ возможных строк длины $n$ с~вероятностью $\frac{1}{N}$), то $I(X) = \log_2(N) = 8n$ бит, то есть $n$ октетов.
% 
% То есть средняя длина кода $|code(X)|$ не может быть меньше $n$ ни для какого кодирования:
% \termin{любой алгоритм сжатия некоторые сообщения укорачивает, а~некоторые "--- удлиняет.}

% Свойства алгоритмов сжатия: а) степень сжатия в~наилучшем случае; б) сжатие/увеличение

Если источник~$X$ порождает блоки длины $N$ бит с~равной вероятностью $\left( p=\frac{1}{2^N} \right)$, он неизбыточен $\to$
% 
% $\to$ 
не~существует такого алгоритма сжатия, который сжимает \termin{любой} блок длины $N$.
% \smallskip
\medskip

Любой алгоритм сжатия сжимает часто встречающиеся блоки данных за счёт того, что более редкие увеличиваются в~размерах.

\end{adjustwidth}
\end{frame}




\subsection{Последовательность, поток, блок}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-1.5em}{-1.8em}
\setlength{\parskip}{0.\parskip}
\small
\setbeamertemplate{itemize/enumerate body begin}{\small\setlistspacing{1}{0.5ex}}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
% \setlength{\parskip}{\smallskipamount} 
% \small
% \setbeamertemplate{itemize/enumerate body begin}{\small}
% \setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\leftmargini}{2ex} 


Источник $X$ генерирует \termin{входную последовательность} $C = c_1c_2\ldots c_n\ldots$, $c_i \in A$ "--- символы пронумерованы (есть~«предыду­щий» и~«последующий»).
\vfill

\termin{Типы входной последовательности / алгоритмы сжатия по её типу}
\begin{enumerate}
\item \termin{блок} "--- конечная входная последовательность (произвольный доступ);

\item \termin{поток} "--- с~неизвестными границами (последо­вательный доступ).
\end{enumerate}

% {Алгоритмы сжатия} по типу входной последовательности:
% \vspace{-1.5\parskip}

\begin{enumerate}
\item блочные "--- статистика всего блока добавляется к~сжатому блоку;
\item поточные  (адаптивные)  "--- статистика вычисляется только для уже обработанной части потока, «на лету» \textterminblue{$\implies$ нестационарная модель $X$}.
% ,  для уже обработанных данных. 

\end{enumerate}
\vfill

$X$ неизвестен $\Rightarrow$ строится \termin{модель источника} по %входной последовательности.
догадкам и~сообщению $x$.

% \medskip
\vfill

\termin{Свойства алгоритмов сжатия:}
\begin{enumerate}
\item степень сжатия $\frac{|X|}{|code(X)|}$: в~среднем по источнику; $\frac{|X|}{|code(X)|} \leqslant \frac{|X|}{|I(X)|}$;
модель $X$ для оценки $|code(x)|$ снизу для конкретной реализации может отличаться от исходной модели \rlap{\textterminblue{(ср. Хаффман блочный и~адаптивный);}}
% $\left(\text{в~среднем по источнику;~} \frac{|X|}{|code(X)|} \geqslant \frac{|X|}{|I(X)|}\right)$
\item \termin{степень увеличения размера в~наихудшем случае;}

\item скорость сжатия и~разжатия. 
\end{enumerate}
% \medskip


\end{adjustwidth}
\end{frame}


% \subsection{Оптимальное кодирование источника $X$}
% \begin{frame}{\insertsubsection}
% % \begin{adjustwidth}{-1.em}{-1.5em}
% \small
% \setlength{\leftmargini}{0em} 
% \setlength{\parskip}{0.3\parskip} 
% 
% Пусть $X$ порождает последовательность из $2^N$ возможных символов.
% 
% \begin{enumerate}
% \item Равновероятный источник ($I(X)=N$) "--- кодирование отдельных символов кодами фиксированной ширины $N$ бит.
% % (нет избыточности).
% 
% \item Стационарный источник без~памяти, порождающий символы с~разными постоянными вероятностями ($I(X)<N$) "--- кодирование отдельных символов кодами переменной ширины: коды Хаффмана, методы~семейства арифметического кодирования.
% 
% \item Стационарный источник с~памятью, порождающий символы с~вероятностями, зависящими от контекста ($I(X)<N$) "--- кодирование сочетаний символов: словарные методы \mbox{семейства LZ77 (словарь=текст)} и~семейства LZ78 (отдельный словарь в~виде дерева/таблицы).
% 
% \end{enumerate}
% 
% Если изначально каждый символ записан кодом фиксированной ширины из $N$ бит $\Rightarrow$ сжатие для \enumilike{2} и~\enumilike{3}.
% 
% % Степень сжатия $\frac{|X|}{|code(X)|}$ оценивается на некоторой выборке файлов;
% 
% % \end{adjustwidth}
% \end{frame}




\subsection{Методы кодирования, коды и~алгоритмы}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-4.5em}{-4.5em}
\small
\setbeamertemplate{itemize/enumerate body begin}{\small\setlistspacing{1}{0.5ex}}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\leftmargini}{0em} 
\setlength{\leftmarginii}{0em} 
\setlength{\parskip}{0.3\parskip} 

Далее рассматриваются \termin{методы сжатия без контекста:} Шеннона, Шеннона"--~Фано, Хаффмана, арифметический (AC);  
\termin{методы сжатия с~учётом контекста:} RLE, LZ77, LZ78
и~\termin{методы защиты от помех:} Хэмминга и~Рида"--~Соломона.

\begin{enumerate}
\item из них только метод Шеннона [не используется] однозначно определяет блочный \termin{код} и~\termin{алгоритм} его построения
"---
но уже для поточных реализаций %метода Шеннона 
есть несколько вариантов;
% (не реализуемые из-за );

\vfill

\item для Хаффмана есть несколько вариантов блочных кодов %одной длины 
% (сортировка по умолчанию, нумерация ветвей, нормировка частот) 
% и~почти столько же 
(каждый "--- несколько поточных), % одной длины, % (сортировка по умолчанию, нумерация ветвей), 
\mbox{причём для каждого кода Хаффмана есть как минимум два разных алгоритма его построения;} % (направление сортировки по убыванию или возрастанию частоты);

\vfill

\item для Шеннона"--~Фано [не используется] "--- несколько блочных кодов (+ поточные, + разные алгоритмы), \mbox{причём  у~разных блочных кодов Шеннона"--~Фано различается длина;}

\vfill

\item для AC, RLE, LZ78, Хэмминга, Рида"--~Соломона "--- десятки кодов разной длины \rlap{и~алгоритмов;}

\vfill


\item для LZ77 "--- сотни кодов, и~для каждого кода "--- сотни алгоритмов.

\end{enumerate}
Поэтому хотя в~литературе (а~также на лекциях и~семинарах) употребляются для краткости названия «код Хаффмана», «алгоритм Хаффмана» и~т.\,п. 
"--- всегда необходимо помнить, что это \termin{метод,} порождающий  \termin{семейство кодов} и~\termin{семейство алгоритмов.}

\end{adjustwidth}
\end{frame}




\input{\SRCROOTPATH/pres-sections/02_compress_prefix.tex}

\section{Семинар: подготовка к~КР1}
\begin{frame}{\insertsection}
% \subsection{Семинар: подготовка к~КР1}
% \begin{frame}{\insertsubsection}

Для сообщения
%
% $C = $
% \\
\texttt{%
% FFF0\,0000\,0123\,4567~89AB\,CDEF\,FFF0\,FFF0~0000\,0000\,0000\,0000~\\
% 1122\,3344\,5566\,7788~99AA\,BBCC\,DDEE\,FFF0
% \text{ЗЕЛЕНО~НЕБО~НЛО}
$m = $
3242\,5675\,2067\,5462
}

\begin{enumerate}
\item оцените суммарное количество информации согласно модели «источник без памяти» (вероятности символов оцениваются по сообщению);

\item закодируйте методами: Хаффмана, Шеннона"--~Фано, Шеннона (укажите порядок сортировки по умолчанию "--- при равных частотах); 

\item сравните длины кодов друг с~другом и~с~количеством информации.


\end{enumerate}

В~байте три бита; символы первичного алфавита "--- байты.


\end{frame}

\makethanks
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
