
\section{Сжатие без учёта контекста}

\subsection{«Энтропийное сжатие» vs «сжатие без учёта контекста»}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
% \footnotesize
% \setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
% \setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}
\small
\setbeamertemplate{itemize/enumerate body begin}{\small}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\parskip}{0.\parskip}
\setlength{\leftmargini}{0em} 
\setlength{\leftmarginii}{0em} 
\setlength{\leftmarginiii}{1em} 

Энтропийные методы сжатия "--- Хаффмана (%неиспользуемые 
предки: Шеннона, Шеннона"--~Фано) и~AC:
$|code(x)| \to I_X(x)$ 
для всех $x  = c_1 c_2 \ldots c_n$ из $X$;
и~даже $|code(c_i)| \to I_X(c_i|c_1 c_2 \ldots c_{i-1})$
% коды символов строятся по вероятностям из $X$

\vfill

\begin{enumerate}
\item Канонический вариант "--- блочный без учёта контекста:
\begin{itemize}
\item  одномерный массив вероятностей $p(a_j)$ оценивается по $x$ %(модель стационарная без памяти)
и~сохраняется %в~архив 
вместе с~$code(x)$;

\item одно дерево Хаффмана %и~один набор кодов $|code(a_j)|$ 
для файла $x$.
\end{itemize}


\vfill



\item 
Поточные (адаптивные) варианты без учёта контекста:
% Поточные (адаптивные)  без учёта контекста [$code(x)$ длиннее блочного, но не требуют сохранения  $p(a_j)$ $\implies$ используются]:

\begin{itemize}
\item при кодировании первого символа $c_1$ считаем 
% $\forall j, k{:} ~~ p(a_j) = p(a_k) = \frac{1}{|A|}$ 
все $a_j$ равновероятными
% (кодируем байт $c_1$ байтом); %  $c_1$); << а это как реализовать
% (как есть);
(байт $c_1$ "--- байтом); 

\item перед кодированием каждого следующего $c_i$ (варианты: через ... символов; как именно)
\termin{пересчитываем} вероятности $p(a_j)$ по $c_1 c_2 \ldots c_{i-1}$
и~%пересчитываем 
новое
дерево Хаффмана. % и~коды;

\end{itemize}
Чуть длиннее и~медленнее блочного, но не требуют сохранения  $p(a_j)$ $\implies$ используются.


\hrulefill

\vfill

\hspace*{-2em}
Теоретически \termin{энтропийное сжатие с~учётом контекста} возможно, на практике не используется:

\item Блочный вариант с~учётом контекста (предыстории в~$N$ символов):

\begin{itemize}
\item  \termin{$(N+1)$-мерный массив} условных вероятностей $p(a_j| a_k a_l \ldots a_m)$;
% оценивается по всему файлу $x$ (модель Маркова $N$ порядка)
% и~сохраняется в~архив вместе с~$code(x)$;
% 
% \item 
\rlap{первые %$N$ символов 
$c_1 c_2 \ldots c_N$ "--- как есть; % (вар-ты $c_2$...);
}

\item далее для каждого  $c_i$ "--- из $p(a_j| c_{i-N} \ldots c_{i-1})$ строится новое дерево Хаффмана; % и~новые коды;

\end{itemize}


\item Поточные варианты с~учётом контекста "--- пересчитываем условные $p(a_j| a_k a_l \ldots a_m)$ в~процессе.
\end{enumerate}

% % $(N+1)$-мерные частоты "--- невыгодно; пересчёт = несжатое начало $\implies$ 
% На практике
% энтропийное кодирование с~учётом контекста не используется.

\end{adjustwidth}
\end{frame}

% % \section{Источник без памяти}
% \subsection{Модель источника --- стационарный без памяти}
% \begin{frame}{\insertsubsection}
% \begin{adjustwidth}{-5em}{-5em}
% % \small
% % \footnotesize
% \setlength{\parskip}{0.\parskip}
% 
% Модель источника $X$ для сжатия  без контекста "--- стационарный источник без памяти, \mbox{строится по~кодируемому сообщению~$C$:}
% % \vspace{-\baselineskip}
% \begin{enumerate}
% \item кодируемое сообщение "--- $C \in A_1^+$, то есть
% %  "--- цепочка символов первичного алфавита: 
%  $C = c_1 \ldots c_n, ~ c_i \in A_1$
% \mbox{(на практике символы первичного алфавита $a \in A_1$ "--- $k$"=битные байты);}
% 
% \item символы 
% % первичного алфавита $x \in A_1$ 
% считаются независимыми:
% % (сообщение рассматривается как источник данных без памяти);
% $p(a) = const$ \mbox{(но~$p(a_i) \neq p(a_j)$ в~общем случае для $a_i, a_j \in A_1$);}
% 
% \item их вероятности оцениваются по частотам в~сообщении~$C$.
% % $p(x) = \frac{\nu_x}{\sum_{y \in C} \nu_y}$;
% 
% % \item количество информации $I(a_i)$ (как и~суммарное $I(C)$, и~среднее источника $I(X)$) оценивается исходя из~оценок $p(a_i)$.
% 
% \end{enumerate}
% \vspace{-0.5\baselineskip}
% 
% \hrulefill
% 
% % Если $\forall a_i, a_j \in A_1$ верно $p(a_i) = p(a_j)$ "--- модель без памяти $X$ не~избыточна, энтропийное сжатие не уменьшит объёма;
% % (модель другого типа может оказаться избыточной);
% % если~вероятности символов (байтов) не равны друг другу (и~$\frac{1}{256}$)
% % "--- энтропийное сжатие уменьшит объём данных приблизительно до \rlap{$I(X)$.}
% % % (плюс заголовок для корректного разжатия).
% \begin{itemize}
% \item Если $\forall a_i, a_j \in A_1$ верно $p(a_i) = p(a_j) = \frac{1}{|A|} =\frac{1}{2^k} =  \frac{1}{256}$ "--- модель без памяти $X$ не~избыточна, энтропийное сжатие не уменьшит объёма данных;
% \item если~$p(a_i) \neq p(a_j)$
% "--- энтропийное сжатие уменьшит объём в~идеале до $\approx I_X(C)$.
% \end{itemize}
% \termin{Для разжатия нужна $X$} (массив $p_j$, обычно в~виде частот $\nu_j \in \Naturalset\cup\{0\}$).
% \vspace{-0.5\baselineskip}
% 
% \hrulefill
% 
% Для ЭВМ $k=8$ ($A_1 = \{\hex{00}, \ldots, \hex{FF}\}$), для задач на доске $k=3$ ($A_1 = \{\hex{0}, \ldots, \hex{7}\}$).
% 
% \vspace{-0.5\baselineskip}
% \end{adjustwidth}
% \end{frame}

\subsection{Алфавитное префиксное кодирование}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
% \footnotesize
% \setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
% \setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}
\setlength{\leftmargini}{0ex} 
\setlength{\parskip}{0.3\parskip}


\begin{enumerate}
% \item Символы первичного алфавита $x \in A_1$ считаются независимыми (сообщение рассматривается как источник данных без памяти);
\item Каждому символу $a \in A_1$
сопоставляется код $code(a) \in A_2^+$,
для~двоичного кодирования "--- $A_2 = \{0, 1\}$ и~$code(a)$ "--- префиксный код из $0$ и~$1$.

\item Длина кода $code(a)$ должна быть как можно ближе к~$I(a)$ (для~двоичного кодирования "--- в~битах).
\end{enumerate}

Префиксный код = дерево
% \hfill
% \includegraphics[width=0.5\linewidth,valign=c]{02_sf_t}

Оптимальный код "--- сбалансированное с~учётом весов дерево.
% $|code(a)| \approx I(a)$

\hrulefill

Результат алфавитного префиксного кодирования "--- битовая строка произвольной длины, в~общем случае некратной длине байта.

При записи битовой строки в~файл последний байт может быть неполным $\implies$ дополняется незначащими битами, обычно нулями.

\end{adjustwidth}
\end{frame}

% \section{Эффективное кодирование}
% http://compress.ru/article.aspx?id=23664#06
% Пахомов\,С.

\subsection{Модель, первичный алфавит, сортировка при равных частотах}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
\setlength{\leftmargini}{0ex} 
\small 
\setbeamertemplate{itemize/enumerate body begin}{\small}
\setbeamertemplate{itemize/enumerate subbody begin}{\small}
\setlength{\parskip}{0.3\parskip}

Символы первичного алфавита = байты: $A_1 = \{0, 1, ... N\}, N = |A|-1$
\textterminblue{(возможно, не все).}

\termin{Положение сжатия без учёта контекста:}

Модель "--- стационарный без памяти источник $\implies$ задаётся постоянными $(p_0, p_1, ..., p_N)$;
\\
в~алгоритмах для ЭВМ "--- \termin{целочисленные частоты $\bm{(\nu_0, \nu_1, ..., \nu_N)}$:} $p_i = \dfrac{\nu_i}{\nu_0 + \nu_1 +...+ \nu_N}$, 
\\
\textterminblue{при оценивании по файлу частота $\nu_i$ не обязательно равна количеству вхождений $count(i)$ байта $i$ в~исходном тексте, но 
$\nu_0:\nu_1:...:\nu_N \approx count(0):count(1):...:count(N)$.}

\vfill


\termin{Допущения ниже:}

\begin{itemize}


\item Построение дерева громоздко $\implies$ рассматриваем на примере 3-битного байта 
% ($2^3 = 8$-символьного алфавита $A_1 = \{0, 1, ..., 7\}$,
($2^3 = 8$-символьный алфавит $A_1 = \{0, 1, ..., 7\}$,
длина файла кратна 3 битам).
% %
% Для наглядности %будем 
% иногда% обозначать
% : 
% \begin{tabular}{@{}l@{}}
% \texttt{01234567}\\
% \texttt{abcdefgh}
% \end{tabular}
\item Сортировка символов "--- по убыванию частот. 
Для кодов  Шеннона и~AC это принципиально;
% принципиально; 
для кодов Хаффмана и~Шеннона"--~Фано "--- из единообразия.

\item При сортировке символов по убыванию частот при $\nu_i=\nu_j$ порядок не определён $\implies$~определим, что \termin{при равных частотах} 
$0 \succ 1 \succ ... \succ N$
\\(здесь «$i \succ j$» = «при $\nu_i=\nu_j$ сортируем как если $\nu_i>\nu_j$»)
\\для Хаффмана определим  \termin{при равных частотах} 
% $0 \succ 1 \succ ... \succ N \succ  ... \succ S_2 \succ S_1$
$ ... \succ S_2 \succ S_1 \succ 0 \succ 1 \succ ... \succ N$.
\end{itemize}

\end{adjustwidth}
\end{frame}



\subsection{Исходный текст --- длина, количество информации}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
\setbeamertemplate{itemize/enumerate body begin}{\normalsize}
\setbeamertemplate{itemize/enumerate subbody begin}{\normalsize}
\setlength{\leftmargini}{0ex} 
\setlength{\leftmarginii}{0ex} 

Исходный текст
% \rlap{$x = «7412650044443» = hebcgfaaeeeec ~~ 
% \left( \begin{array}{@{}l@{}}
% {01234567}\\
% {abcdefgh}
% \end{array} \right)$:
% }
$x = «7412650044443»$
% (алфавит "--- трёхбитные байты!):
(алфавит "--- $k$-битные байты, $k=3$!):

\begin{enumerate}

\item длина исходного текста $n = 13$ символов, что составляет 
% $13\cdot3=39$ бит;
$13\cdot k=39$ бит;
\begin{itemize}
\item сохраняется в~заголовке, чтобы при декодировании отсечь незначащие биты в~конце файла;
\end{itemize}

\vfill

\item частоты $(\nu_0, \nu_1, ..., \nu_7) = (2, 1, 1, 1, 5, 1, 1, 1)$:
\begin{itemize}
\item массив частот $(2, 1, 1, 1, 5, 1, 1, 1)$ в~исходном порядке $(\nu_0, \nu_1, ..., \nu_7)$ "--- помещается в~архив и~используется для распаковки файла;
\item %частоты 
% $e(5), a(2), b(1), c(1), d(1), f(1), g(1), h(1)$%
пары $\text{символ}^{\text{частота}}$
% $e^5, a^2, b^1, c^1, d^1, f^1, g^1, h^1$%
$4^5, 0^2, 1^1, 2^1, 3^1, 5^1, 6^1, 7^1$%
, отсортированные по убыванию частот 
(а~при равных "--- согласно $0 \succ 1 \succ ... \succ N$)
"--- используются для построения кодов;
\end{itemize}



\vfill

\item общее (не среднее на символ!) количество информации (согласно модели без памяти):

$I(x) = - 5\cdot \log_2\frac{5}{13} - 2\cdot \log_2\frac{2}{13} - 6\cdot 1 \cdot \log_2\frac{1}{13} \approx 34,5$ бит

35 бит "--- минимально возможная длина кода $x$ любым алгоритмом без учёта контекста.


\end{enumerate}
\vfill

\end{adjustwidth}
\end{frame}



% \subsection{«Авиакатастрофа» --- длина, количество информации}
% \begin{frame}{\insertsubsection}
% \setlength{\leftmargini}{0ex} 
% 
% Кодируем строку $x = $«авиакатастрофа»:
% 
% \begin{itemize}
% 
% \item первичный алфавит "--- символ=тетрада (4-битный байт доски), длина "--- $n = 14$ тетрад (56 бит);
% 
% пусть есть общепринятая «естественная» кодировка
% 
% {
% % \hspace*{-2em}
% \small
% \textcolor{gray}{Alternative vexillum codicis inf. interpretatio (AVCII):}
% \begin{tabular}{@{}l@{}}
% \texttt{\textvisiblespace,.!?абвгикорстф}\\
% \texttt{0123456789ABCDEF}
% \end{tabular}
% 
% }
% 
% \item используется 9 различных символов, \mbox{частоты {а(5), т(2), в(1), и(1), к(1), с(1), р(1), о(1), ф(1)};}
% 
% \item общее (не среднее на символ!) количество информации в~тексте (согласно модели без памяти):
% 
% $I(x) = - 5\cdot \log_2\frac{5}{14} - 2\cdot \log_2\frac{2}{14} - 7\cdot \log_2\frac{1}{14} \approx 39,7$ бит
% 
% 
% \end{itemize}
% 
% 
% \end{frame}

\section{Исторические коды: Шеннона и~Шеннона-Фано}

% \section{Код Шеннона}
% \subsection{Построение кода Шеннона}
\subsection{Код Шеннона}

\begin{frame}{\insertsubsection}
% \begin{frame}{\insertsection}
\footnotesize
\setlength{\parskip}{0.1\parskip}

Код Шеннона строится не как дерево [но является деревом]:
\begin{enumerate}
\item все символы сортируются по частоте (по убыванию): $a_1, a_2, ... a_{|A|}$, 
$\nu(a_1) \geqslant \nu(a_2) \geqslant... \geqslant \nu(a_{|A|})$;

\item код $a_i$
"--- первые $l_i = \left \lceil{-\log_2 p_i}\right \rceil $
двоичных цифр $\sum_{k=0}^{i-1} p_i$.
\end{enumerate}

{
\scriptsize
% \setlength{\tabcolsep}{1pt}
\def\arraystretch{1.3}

\begin{tabularx}{1\linewidth}{c|l|l|l|l|l}
$a_i$ & $p_i$             &  $I(a_i)=-\log_2 p_i$   & $l_i$ & $\sum_{k=0}^{i-1} p_i$   & код \\\hline
$4$ & $\frac{5}{13} \approx 0,01100...$ & $1,38...$ & 2 &              $0 =      0,00000...$ & 00   \\
$0$ & $\frac{2}{13} \approx 0,00100...$ & $2,70...$ & 3 & $\frac{ 5}{13} \approx 0,01100...$ & 011  \\
$1$ & $\frac{1}{13} \approx 0,00010...$ & $3,70...$ & 4 & $\frac{ 7}{13} \approx 0,10001...$ & 1000 \\
$2$ & $\frac{1}{13} \approx 0,00010...$ & $3,70...$ & 4 & $\frac{ 8}{13} \approx 0,10011...$ & 1001 \\
$3$ & $\frac{1}{13} \approx 0,00010...$ & $3,70...$ & 4 & $\frac{ 9}{13} \approx 0,10110...$ & 1011 \\
$5$ & $\frac{1}{13} \approx 0,00010...$ & $3,70...$ & 4 & $\frac{10}{13} \approx 0,11000...$ & 1100 \\
$6$ & $\frac{1}{13} \approx 0,00010...$ & $3,70...$ & 4 & $\frac{11}{13} \approx 0,11011...$ & 1101 \\
$7$ & $\frac{1}{13} \approx 0,00010...$ & $3,70...$ & 4 & $\frac{12}{13} \approx 0,11101...$ & 1110 \\
\hline
\end{tabularx}

}

$|code(x)| = 5\cdot 2 + 2\cdot 3 + 6\cdot 1\cdot 4 = 40$ бит 
% $= 14$ трёхбитных байтов ($\frac{40}{3}=13\frac{1}{3}$).
$=
\left \lceil{
13\frac{1}{3}
}\right \rceil = 14
$ трёхбитных байтов.
% \\($\frac{40}{3}=13\frac{1}{3}$, последний неполный  и~два незначащих бита, обычно 00).

Исторически первый; не лучше Шеннона"--~Фано.


\end{frame}


% \subsection{Код Шеннона}
% 
% \begin{frame}{\insertsubsection}
% % \begin{frame}{\insertsection}
% \footnotesize
% \setlength{\parskip}{0.1\parskip}
% 
% Код Шеннона строится не как дерево [но является деревом]:
% \begin{enumerate}
% \item все символы сортируются по частоте (по убыванию): $a_1, a_2, ... a_{|A|}$, 
% $\nu(a_1) \geqslant \nu(a_2) \geqslant... \geqslant \nu(a_{|A|})$;
% 
% \item код $a_i$
% "--- первые $l_i = \left \lceil{-\log_2 p_i}\right \rceil $
% двоичных цифр $\sum_{k=0}^{i-1} p_i$.
% \end{enumerate}
% 
% {
% \scriptsize
% % \setlength{\tabcolsep}{1pt}
% \def\arraystretch{1.3}
% 
% \begin{tabularx}{1\linewidth}{c|l|l|l|l}
% $a_i$ & $p_i$ & $\sum_{k=0}^{i-1} p_i$ &  $-\log_2 p_i$  & код \\\hline
% а & $\frac{5}{14} \approx 0,01011...$ & $0 = 0,00000...$ & $1,48...$ & 00 \\
% т & $\frac{2}{14} \approx 0,00100...$ & $\frac{5}{14} \approx 0,01011...$ & $2,81...$ & 010 \\
% в & $\frac{1}{14} \approx 0,00010...$ & $\frac{7}{14} \approx 0,10000...$ & $3,81...$ & 1000 \\
% и & $\frac{1}{14} \approx 0,00010...$ & $\frac{8}{14} \approx 0,10010...$ & $3,81...$ & 1001 \\
% к & $\frac{1}{14} \approx 0,00010...$ & $\frac{9}{14} \approx 0,10100...$ & $3,81...$ & 1010 \\
% с & $\frac{1}{14} \approx 0,00010...$ & $\frac{10}{14} \approx 0,10110...$ & $3,81...$ & 1011 \\
% р & $\frac{1}{14} \approx 0,00010...$ & $\frac{11}{14} \approx 0,11001...$ & $3,81...$ & 1100 \\
% о & $\frac{1}{14} \approx 0,00010...$ & $\frac{12}{14} \approx 0,11011...$ & $3,81...$ & 1101 \\
% ф & $\frac{1}{14} \approx 0,00010...$ & $\frac{13}{14} \approx 0,11101...$ & $3,81...$ & 1110 \\
% \hline
% \end{tabularx}
% 
% }
% 
% $|code(x)| = 5\cdot 2 + 2\cdot 3 + 7\cdot 4 = 44$ бита $= 11$ тетрад
% 
% Исторически первый; не лучше Шеннона"--~Фано.
% 
% 
% \end{frame}




% \section{Код Шеннона--Фано}


\subsection{Построение дерева Шеннона--Фано}
\begin{frame}{\insertsubsection}
Дерево Шеннона"--~Фано строится \termin{сверху вниз} (от~корневого узла к~листовым):

\begin{enumerate}
\item 
% На первом шаге 
все символы % исходной информационной последовательности 
сортируются %по убыванию или возрастанию вероятностей их появления (частоты их появления), 
по частоте; %после чего 
\item
упорядоченный ряд символов в~некотором месте 
делится на две части  так, чтобы в каждой из них сумма частот символов была примерно одинакова (без пересортировки!);

\item новое деление.
\end{enumerate}

Исторически первый близкий к~оптимальному префиксный код.

Не лучше кода Хаффмана по степени сжатия и~примерно аналогичен по скорости кодирования/декодирования.

\end{frame}


\subsection{Кодирование $x$ методом Шеннона--Фано}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
% \setbeamertemplate{itemize/enumerate body begin}{\normalsize}
% \setbeamertemplate{itemize/enumerate subbody begin}{\normalsize}
\setlength{\leftmargini}{0ex} 
\setlength{\leftmarginii}{0ex} 
% \small 
% \setbeamertemplate{itemize/enumerate body begin}{\small}
% \setbeamertemplate{itemize/enumerate subbody begin}{\small}
% \setlength{\parskip}{0.3\parskip}
\footnotesize 
\setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
\setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}
\setlength{\parskip}{0.1\parskip}

\label{alg_s_f}

Не определено, какая ветвь получает бит 0, а~какая 1. 
% Пусть следующая цифра кода первой подгруппы ($s_1$) 0, второй ($s_2$) 1.
Пусть первая подгруппа ($s_1$) "--- 0, вторая ($s_2$) "--- 1.


Неточно определён алгоритм деления $s$ на $s_1 + s_2$. Основные варианты уточнений:
\begin{enumerate}
\item $\displaystyle
%s_1 \leqslant s_2
\min_{s_1 \leqslant s_2} |s_2 - s_1|
$
"--- более частые символы получают более короткие коды, быстрее расчёт;

\item $\displaystyle \min |s_2 - s_1|$, если он достигается в~одной точке; если в двух:
$\displaystyle
%s_1 \leqslant s_2
\min_{s_1 \leqslant s_2} |s_2 - s_1|;
$
"--- короче код сообщения.

\end{enumerate}

Воспользуемся \enumilike{2}:

% 1)  
% $\Big(e^5, a^2, b^1, c^1, d^1, f^1, g^1, h^1\Big)^{13} 
% \to 
% \underbrace{\Big(e^5, a^2\Big)^{7}}_{\text{коды начинаются с~0}} + \underbrace{\Big(b^1, c^1, d^1, f^1, g^1, h^1\Big)^{6}}_{\text{коды начинаются с~1}}$
% 
% 2) $\underbrace{\Big(e^5, a^2\Big)^{7}}_{\text{коды начинаются с~0}}
% \to
% \underbrace{e^5}_{00} + \underbrace{a^2}_{01}
% $
% и т.\,д.: ~
% $\begin{array}{@{}|c|c|c|c|c|c|c|c|@{}}
% \hline
% e^5 & a^2 & b^1 & c^1 & d^1 & f^1 & g^1 & h^1 \\\hline
% \multicolumn{2}{|c|}{0} & \multicolumn{6}{c|}{1} \\\hline
% % 0 & 1                   & \multicolumn{3}{c|}{0} & \multicolumn{3}{c|}{1} \\\hhline{~~------}
% 0 & 1                   & \multicolumn{3}{c|}{0} & \multicolumn{3}{c|}{1} \\\cline{3-8} 
%   &                     & 0 & \multicolumn{2}{c|}{1} & 0 &\multicolumn{2}{c|}{1} \\\cline{4-5} \cline{7-8} 
%   & & & 0 & 1 && 0 & 1 \\\hline
% 00  & 01  & 100 & 1010 & 1011 & 110 & 1110 & 1111 \\\hline
% \end{array}$

1)  
$\Big(4^5, 0^2, 1^1, 2^1, 3^1, 5^1, 6^1, 7^1\Big)^{13} 
\to 
\underbrace{\Big(4^5, 0^2\Big)^{7}}_{\text{коды начинаются с~0}} + \underbrace{\Big(1^1, 2^1, 3^1, 5^1, 6^1, 7^1\Big)^{6}}_{\text{коды начинаются с~1}}$

2) $\underbrace{\Big(4^5, 0^2\Big)^{7}}_{\text{коды начинаются с~0}}
\to
\underbrace{4^5}_{00} + \underbrace{0^2}_{01}
$
и т.\,д.: ~
$\begin{array}{@{}|c|c|c|c|c|c|c|c|@{}}
\hline
4^5 & 0^2 & 1^1 & 2^1 & 3^1 & 5^1 & 6^1 & 7^1 \\\hline
\multicolumn{2}{|c|}{0} & \multicolumn{6}{c|}{1} \\\hline
% 0 & 1                   & \multicolumn{3}{c|}{0} & \multicolumn{3}{c|}{1} \\\hhline{~~------}
0 & 1                   & \multicolumn{3}{c|}{0} & \multicolumn{3}{c|}{1} \\\cline{3-8} 
  &                     & 0 & \multicolumn{2}{c|}{1} & 0 &\multicolumn{2}{c|}{1} \\\cline{4-5} \cline{7-8} 
  & & & 0 & 1 && 0 & 1 \\\hline
00  & 01  & 100 & 1010 & 1011 & 110 & 1110 & 1111 \\\hline
\end{array}$




$code(x)=
%hebcgfaaeeeec
111100100...
$

$|code(x)| = 5\cdot 2 + 2\cdot 2 + 2\cdot 1 \cdot 3 + 4\cdot 1 \cdot 4 = 36$ бит
$= 12$ трёхбитных байтов


\end{adjustwidth}
\end{frame}



% \subsection{«Авиакатастрофа» --- кодирование   Шеннона--Фано}
% \begin{frame}{\insertsubsection}
% % «авиакатастрофа» $\to$  {а(5), т(2), в(1), и(1), к(1), с(1), р(1), о(1), ф(1)}
% % \includegraphics[width=1\linewidth,valign=t]{01_sf}
% 
% \hspace*{-2em}\includegraphics[width=0.9\linewidth,valign=t]{02_sf}
% \hfill\parbox[t]{0.15\linewidth} {a {00}
% 
% т­ {01}
% 
% в­ {100}
% 
% и­ {1010}
% 
% к­ {1011}
% 
% с­ {1100}
% 
% р­ {1101}
% 
% о­ {1110}
% 
% ф­ {1111}
% }
% 
% $code(x)=
% 00100101000101100010011000111011110111100
% $
% 
% $|code(x)| = 5\cdot 2 + 2\cdot 2 + 3 + 6\cdot 4 = 41$ бит
% 
% \end{frame}


\section{Код Хаффмана}

\subsection{Построение дерева Хаффмана}
\begin{frame}{\insertsubsection}
Дерево Хаффмана строится \termin{снизу вверх} (от~листовых узлов к~корневому узлу):

% Алгоритм Хаффмана подразумевает построение кодового дерева в обратном порядке, то есть снизу вверх (от листовых узлов к корневому узлу).

{
\setlength{\parskip}{0\parskip}


\begin{enumerate}
\item 
% На первом шаге 
все символы % исходной информационной последовательности 
сортируются %по убыванию или возрастанию вероятностей их появления (частоты их появления), 
по частоте (по убыванию); %после чего 

\item два 
% самых редких элемента
последних (самых редких) элемента отсортированного списка узлов 
заменяются на~новый элемент % S1
% , которому приписывается повторяемость, равная сумме повторяемостей исходных элементов. 
с~частотой, равной сумме исходных;

\item 
% Затем производится 
новая сортировка. %элементов последовательности в соответствии с их повторяемостью.
\end{enumerate}
На каждом шаге число узлов сокращается на один; узел, полученные на последнем шаге "--- корень дерева.

}

Код Хаффмана имеет минимальную длину среди префиксных.

Не увеличивает размера исходных данных в~худшем случае.
\end{frame}

% \newcommand{\hf}[1]{\raisebox{2ex}{\footnotesize 0} ~~ #1 ~~ \raisebox{2ex}{\footnotesize 1}}
\newcommand{\hf}[1]{\overset{0}{} ~~ #1 ~~ \overset{1}{}}
% \newcommand{\hf}[1]{\raisebox{2ex}{$\overset{0}{}$} ~~ #1 ~~ \raisebox{2ex}{$\overset{1}{}$}}


\subsection{Кодирование $x$ методом Хаффмана, 
% $ ... \succ S_2 \succ S_1 \succ (0=a) \succ (1=b) \succ ... \succ (7=h)$
$ ... \succ S_2 \succ S_1 \succ 0 \succ 1 \succ ... \succ 7$
}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
\setlength{\leftmargini}{0ex} 
\setlength{\leftmarginii}{0ex} 
\footnotesize 
\setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
\setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}
\setlength{\parskip}{0.1\parskip}

\label{alg_hf}

Не определено, какая ветвь дерева получает бит 0, а~какая 1. 
Пусть 0, 1 "---  слева направо. %0 "--- предпоследний, 1 "--- последний.

\vfill

% 1) $e^5, a^2, b^1, c^1, d^1, f^1, \underbrace{g^1, h^1}_{\hf{S_1^2}}$ "--- последний бит кода $g^1$ "--- 0, последний бит кода $h^1$ "--- 1
% 
% 2) $e^5, S_1^2, a^2, b^1, c^1, \underbrace{d^1, f^1}_{\hf{S_2^2}}$ 
% 
% 3) $e^5, S_2^2, S_1^2, a^2, \underbrace{b^1, c^1}_{\hf{S_3^2}}$ 
% 
% 4) $e^5, S_3^2, S_2^2, \underbrace{S_1^2, a^2}_{\hf{S_4^4}}$ 
% 
% 5) $e^5, S_4^4, \underbrace{S_3^2, S_2^2}_{\hf{S_5^4}}$ 
% 
% 6) $e^5, \underbrace{S_5^4, S_4^4}_{\hf{S_6^8}}$ 
% 
% 7) $\underbrace{S_6^8, e^5}_{\hf{S_7^{13}}}$ 
% 
% \vspace{-8\baselineskip}
% \begin{adjustwidth}{+13em}{0em}
% \setlength{\parskip}{10\parskip}
% {
% $\begin{array}{@{}|c|c|c|c|c|c|c|c|@{}}
% \hline
% e^5 & a^2 & b^1 & c^1 & d^1 & f^1 & g^1 & h^1 \\\hline
% 1  & 011  & 0000 & 0001 & 0010 & 0011 & 0100 & 0101 \\\hline
% \end{array}$
% }


1) $4^5, 0^2, 1^1, 2^1, 3^1, 5^1, \underbrace{6^1, 7^1}_{\hf{S_1^2}}$ "--- последний бит кода $6^1$ "--- 0, последний бит кода $7^1$ "--- 1

2) $4^5, S_1^2, 0^2, 1^1, 2^1, \underbrace{3^1, 5^1}_{\hf{S_2^2}}$ 

3) $4^5, S_2^2, S_1^2, 0^2, \underbrace{1^1, 2^1}_{\hf{S_3^2}}$ 

4) $4^5, S_3^2, S_2^2, \underbrace{S_1^2, 0^2}_{\hf{S_4^4}}$ 

5) $4^5, S_4^4, \underbrace{S_3^2, S_2^2}_{\hf{S_5^4}}$ 

6) $4^5, \underbrace{S_5^4, S_4^4}_{\hf{S_6^8}}$ 

7) $\underbrace{S_6^8, 4^5}_{\hf{S_7^{13}}}$ 

\vspace{-8\baselineskip}
\begin{adjustwidth}{+13em}{0em}
\setlength{\parskip}{10\parskip}
{
$\begin{array}{@{}|c|c|c|c|c|c|c|c|@{}}
\hline
4^5 & 0^2 & 1^1 & 2^1 & 3^1 & 5^1 & 6^1 & 7^1 \\\hline
1  & 011  & 0000 & 0001 & 0010 & 0011 & 0100 & 0101 \\\hline
\end{array}$
}


$code(x)=
% %hebcgfaaeeeec
% 010110000...
0101 1 0000 0001 0100 0011 011 011 1 1 1 1 0010
$

$|code(x)| = 5\cdot 1 + 2\cdot 3 + 6 \cdot 1 \cdot 4 = 35$ бит
$=
\left \lceil{
11\frac{2}{3}
}\right \rceil = 12
$ трёхбитных байтов.
\end{adjustwidth}


\end{adjustwidth}
\end{frame}


\subsection{Код Хаффмана и~архив с~кодами Хаффмана}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-5em}{-5em}
% \setlength{\parskip}{0.5\parskip}
\footnotesize
\setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
\setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}
\setlength{\leftmargini}{0ex}
\setlength{\leftmarginii}{3ex}
\setlength{\parskip}{0\parskip}


% Исходный файл
% $m = 7412 6500 4444 3$  из $n=13_{10}=15_8$ трёхбитных байтов, 
% % оценка $I$ по модели без памяти $I(m)\approx 34,5$ бит;
% \rlap{код Хаффмана:} % сообщения $m$:
% \\
% $
% % \text{Хф}(m)=
% 0101 1 0000 0001 0100 0011 011 011 1 1 1 1 0010$
% длиной 35 бит будет дополнен до $\geqslant12$ байтов:

Код Хаффмана $0101 1 0000 0001 0100 0011 011 011 1 1 1 1 0010$ длиной 35 бит будет дополнен до $\geqslant12$ байтов:
\\
$
010\,1 1 0\,000\, 000\,1 01\,00 0\,011\, 011\, 011\, 1 1 1\, 1 00\,10 \textcolor{gray!70}{0}
~\text{(биты)}
=
260050333744
~\text{(байты)}
$

% Пусть формат имеет вид (смещение и размер полей "--- в~$k=3$-битных байтах):

\vfill

\begin{tabularx}{1\linewidth}{|l|l|l@{~}X|}
\hline
Смещение & Размер & Описание &  \\\hline
0    & 4 & Сигнатура+версия формата &  всегда 0711  \\\hline
4    & 1 & № алгоритма сжатия с контекстом & $0$ "--- нет сжатия      \\\hline
5    & 1 & № алгоритма сжатия без контекста & $0$ "--- нет сжатия, \hfill $1$ "---  Шеннона, 
\mbox{$2$ "--- вар-т Шеннона"--~Фано со с.~\pageref{alg_s_f},}     
$3$ "--- вар-т Хаффмана  со с.~\pageref{alg_hf}    
\\\hline
6    & 1 & № алгоритма шифрования & $0$ "--- нет шифрования      \\\hline
7    & 1 & № алгоритма защиты от помех & $0$ "--- нет защиты  от помех    \\\hline
8    & 4 & Исходная длина файла $n$ & беззнаковое 12-битное целое \\\hline
% 12   & 8 & 
% % \multicolumn{2}{l|}{Массив частот $\vec\nu = (\nu_0, \nu_1, ..., \nu_7)$  как беззнаковые 3-битные целые} 
% Массив частот $\vec\nu = (\nu_0, \nu_1, ..., \nu_7)$ & как беззнаковые 3-битные целые  
% \\\hline
% 20   
% % & до конца файла & \multicolumn{2}{l|}{Сжатые данные алгоритма сжатия без контекста $0-3$}
% & ? & Сжатые данные & выравнивание на 1 байт
12    & 4 & Резерв & %всегда 0000 
\\\hline
16   & 8 & Массив частот $\vec\nu = (\nu(0), \nu(1), ..., \nu(7))$ & беззнаковые 3-битные целые  \\\hline
24& до конца & Сжатые данные & выравнивание на 1 байт
\\\hline
\end{tabularx}
\vfill

% \begin{tabularx}{1\linewidth}{|l|l|l|lX|}
% \hline
% Смещение & Размер &  & Описание &  \\\hline
% 0    & 4 && Сигнатура+версия формата &  всегда 0712  \\\hline
% 4    & 1 & $cw$ & № алгоритма сжатия с контекстом & $0$ "--- нет сжатия      \\\hline
% 5    & 1 & $cl$ & № алгоритма сжатия без контекста & $0$ "--- нет сжатия, \hfill $1$ "---  Шеннона, 
% \mbox{$2$ "--- вар-т Шеннона"--~Фано со стр.~\pageref{alg_s_f},}     
% $3$ "--- вар-т Хаффмана  со стр.~\pageref{alg_hf}    
% \\\hline
% 6    & 1 & $cs$ & № алгоритма шифрования & $0$ "--- нет шифрования      \\\hline
% 7    & 1 & $cn$ & № алгоритма защиты от помех & $0$ "--- нет защиты     \\\hline
% 8    & 4 & $n$ & Исходная длина файла %(до всех видов кодирования) 
% & беззнаковое 12-битное целое \\\hline
% 12   & 8 && 
% % \multicolumn{2}{l|}{Массив частот $\vec\nu = (\nu_0, \nu_1, ..., \nu_7)$  как беззнаковые 3-битные целые} 
% Массив частот $\vec\nu = (\nu_0, \nu_1, ..., \nu_7)$ & беззнаковые 3-битные целые  
% \\\hline
% 20   
% % & до конца файла & \multicolumn{2}{l|}{Сжатые данные алгоритма сжатия без контекста $0-3$}
% & ? && Сжатые данные & выравнивание на 1 байт
% \\\hline
% \end{tabularx}





% Для декодирования нужны ещё $n$ (запишем 12 битами = 4 байтами) и~массив частот $\vec\nu$:
% \begin{enumerate}
% \item Для определения формата нужна сигнатура+версия (пусть здесь это 0712);
% \item для выбора декодера "--- № алгоритма, пусть здесь это:
% \begin{itemize}
% \item $0$ для сжатия с контекстом (нет сжатия);
% \item $3$ для сжатия без контекста (описанная выше реализация Хаффмана);
% \item $0$ для шифрования (нет шифрования);
% \item $0$ для защиты от помех (нет защиты);
% \end{itemize}
% 
% \item для декодирования "--- $n$ (запишем 12 битами = 4 байтами) и~массив частот $\vec\nu$;
% \item пусть формат имеет 
% \end{enumerate}

Только Хаффман с.\,\pageref{alg_hf}: алг.\,0300;
\hfill
исх.\,длина $n=13_{10}=15_8$ трёхбитных байтов%; %записываем 12 битами = 4 байтами
, порядок Intel: $n \sim 5100$;
% \hfill
% $\vec\nu = (2, 1, 1, 1, 5, 1, 1, 1)$
\\
частоты $
% $n \sim 5100,  
\vec\nu \sim 2 1 1 1 5 1 1 1, $ код $
% $15 \sim 5100, 
% ~~2 1 1 1 5 1 1 1, ~~
% % \vec\nu = (2, 1, 1, 1, 5, 1, 1, 1),
260050333744$ \hfill $\to$ \hfill  архив имеет вид $0711  0300  5100  0000    2 1 1 1 5 1 1 1   260050333744$

\vfill

Для удобочитаемости разделяем по 4-байтовым блокам: \hfill $0711 ~ 0300~   5100 ~  0000 ~    2 1 1 1~  5 1 1 1 ~   2600~ 5033~ 3744$

% \vfill
\end{adjustwidth}
\end{frame}

\subsection{Нормировка частот}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-7em}{-6em}

% Ненормированное количество $count(c)$ вхождений символа $c$ в~общем случае может достигать длины файла $n$, 
% поэтому для расчёта кода используются \termin{нормированные} частоты $\nu_c$, и~они же записываются в~файл для восстановления:

Ненормированное $count(c)$ 
% вхождений может достигать $n$ 
может превышать допустимое $\max(\nu(c))$
$\implies$ нормировка: %при $\max(count) > \text{допустимого значения}$:

$\left\{
\begin{array}{@{}l}
\nu_0:\nu_1:...:\nu_N \approx count(0):count(1):...:count(N),\\
\max(\nu_i) = \text{максимальное значение байта} %= N = T-1
.\\
\end{array}
\right.
$

Для $m = 7754\, 4444\, 4444\, 4444\, 4444\, 3333\, 3333\, 3333\, 3333\, 1112$ 
длины $n=%10\cdot4 = 
40_{10}=50_8$
\\
$\overrightarrow{count} = (0, 3, 1, 16, 17, 1, 0, 2)$, но 
$\vec{\nu} = (0, 2, 1, 7, 7, 1, 0, 1)$.

В архив записываются:\setlength{\parskip}{0\parskip}
\begin{itemize}
\item нормированные частоты
$ %50, ~ 
0 2 1 7 7 1 0 1$;
\item
код, рассчитанный по нормированным $\vec{\nu} = (0, 2, 1, 7, 7, 1, 0, 1)$, а~не по исходным $\overrightarrow{count}$.
\end{itemize}
% 
% Для $m = 4444 4444 4444 4$  из $n=13_{10}=15_8$ байтов $I(m) = |code(m)| = 0$:
% 
% $0015, ~~ 0 0 0 0 7 0 0 0$
% 
% частоты для записи одним байтом должны нормироваться.

% Для $m = 7412\, 6500\, 4444\, 3444\, 4444\, 4444\, 4444$  ненормированные частоты $\overrightarrow{count} = (2, 1, 1, 1, 20, 1, 1, 1)$
% не могут быть записаны одним байтом


\end{adjustwidth}
\end{frame}


\subsection{Нулевые частоты и~нормировка частот}
\begin{frame}{\insertsubsection}
\begin{adjustwidth}{-7em}{-6em}
% \small
% % \setbeamertemplate{itemize/enumerate body begin}{\small\setlistspacing{1}{0.5ex}}
% \setbeamertemplate{itemize/enumerate body begin}{\small}
% \setbeamertemplate{itemize/enumerate subbody begin}{\small}
% % % \setlength{\leftmargini}{0em} 
% % \setlength{\leftmarginiii}{0em} 
\footnotesize
\setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
\setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}

% При перенормировке частот $[0, \nu_{\max}] \to [0, Max]$ возможно 

\begin{enumerate}
\item 
% Нулевые значения частот могут быть отброшены% при первой сортировке (как в~примерах на слайдах)
% , и~символы с~нулевыми частотами не получат кода.
По умолчанию байты с~нулевыми $\nu_i$ отбрасываются %(алфавит меньше $2^k$) 
и~не получают кода.
%
Тогда при приведении частот 
$count(i)\in[0, \max(count)] ~\to~ \nu_i\in[0, Max]$ необходимо, чтобы 
% ненулевые малые $count(i)$ не перешли в~нулевые $\nu_i$:
при $count(i)>0$ было $\nu_i>0$:
% (то есть $0 \to 0, ~ 1\to 1, ..., \max(count)\to Max$):
% $
% \nu_i \to \left\{
% \begin{array}{ll}
% 0, & \nu_i = 0,\\
% \mathrm{round}\left( \frac{\nu_i - 1}{\nu_{\max} - 1} \cdot (Max - 1) \right) + 1, & \nu_i \neq 0.
% \end{array}
% \right.
% $

\vfill

\begin{itemize}
\item соотношения всех частот незначительно искажаются:
% ; 
% для $count(i)\approx 1$ искажение немного больше, чем для $count(i)\approx \max(count)$:

% б\'{о}льших частот
$\left\{
\begin{array}{ll}
\nu_i = 0, & count(i) = 0,\\
\nu_i = \mathrm{round}\left( \frac{count(i) - 1}{\max(count) - 1} \cdot (Max - 1) \right) + 1, & count(i) > 0;
\end{array}
\right.
$
\hfill(A)
\vfill

\item %соотношения частот 
для $count(i) > \frac{\max(count)}{Max}$ передаются максимально точно; 
для малых полностью искажаются:

$\left\{
\begin{array}{ll}
\nu_i = 0, & count(i) = 0,\\
\nu_i = 1, & 0 < count(i) \leqslant \frac{\max(count)}{Max},\\
\nu_i = \mathrm{round}\left( \frac{count(i)}{\max(count)} \cdot Max \right), & count(i) > \frac{\max(count)}{Max};
\end{array}
\right.
$
\hfill(B)
\end{itemize}

\vfill
для октетов ($Max = 255$) и~%относительно небольших (
$\dfrac{\max(count)}{\displaystyle\min_{\neq 0}(count)} \leqslant Max$
%) отклонений от~равновероятностности 
обе формулы дают приемлемый результат.
% \vfill

\item 
% Нулевые значения частот могут обрабатываться% по общему алгоритму
% : символы с~нулевыми частотами получат коды, а~код символа с~наименьшей ненулевой частотой (последнего в~сортировке; здесь «$7=h$») удлинится на бит.
Если хочется 
% воспользоваться 
% более простой формулой
% $\nu_i  \to \mathrm{round}\left( \frac{\nu_i}{\nu_{\max}} \cdot {Max} \right).$
$
\begin{array}{ll}
\nu_i = \mathrm{round}\left( \frac{count(i)}{\max(count)} \cdot Max \right)
\end{array}
$
% (ненулевая $count(i)$ может стать нулевой $\nu_i$), 
для всех (возможно $count(i)>0 ~\to~\nu_i = 0$),
то:
\begin{itemize}
\item  необходимо модифицировать алгоритм, чтобы байты с~%нулевыми $\nu_i$
$\nu_i = 0$
получили коды (возможно для Хаффмана и~Шеннона"--~Фано, невозможно для арифметического и~Шеннона); 

\item тогда коды получат и~байты с~$count(i)=0$, а~коды 
$count(i)>0$ удлинятся.

% \item при этом код байта с~наименьшей ненулевой $count(i)$ 
% % им $count(i) \neq 0$
% удлинится на бит $\implies$ код файла удлинится на~$count(i)$ бит;
% % \item в~частности, в~вырожденном случае файла из $n$ одинаковых байтов (см.\,ниже) такой модифицированный алгоритм даст код длины $n$ бит вместо нулевой;

% \item так можно модифицировать алгоритм Хаффмана (и~Шеннона"--~Фано), но не~арифметический кодек (и~не Шеннона).
\end{itemize}



\end{enumerate}
\end{adjustwidth}
\end{frame}

% \section{Вырожденное сообщение, адаптивные алгоритмы, арифметический код}
% \section{Вырожденное сообщение. Арифметический код}


\subsection{Вырожденный случай}
\begin{frame}{\insertsubsection}
\setlength{\parskip}{0.7\parskip}


Для $m = 4444 4444 4444 4$  из $n=13_{10}=15_8$ байтов $I(m) %= |code(m)| 
= 0$:


\begin{itemize}
\item длина кода Шеннона символа $4$ равна нулю, так как $I(m) = 0$;
\item длина кода Хаффмана и Шеннона"--~Фано символа $4$ равна нулю, так как дерево состоит из одного узла (корня $4$) и~нуля ветвей.
\end{itemize}

Длина кода (Хаффмана, Шеннона"--~Фано или Шеннона) всего сообщения из $n$ {одинаковых} символов $4$ также \termin{нулевая.}

Файл архива должен содержать $n$ и~массив частот $\vec\nu$:

$15, ~~ 0 0 0 0 7 0 0 0$

этого достаточно для восстановления такого сообщения.

\end{frame}



% \subsection{«Авиакатастрофа» --- кодирование Хаффмана}
% \begin{frame}{\insertsubsection}
% 
% \includegraphics[width=0.35\linewidth,valign=t]{02_h} 
% \hspace{-2em}
% \includegraphics[width=0.5\linewidth,valign=t]{02_h_t} 
% \hfill\parbox[t]{0.15\linewidth} {a {0}
% 
% т­ {111}
% 
% в­ {1101}
% 
% и­ {11000}
% 
% к­ {11001}
% 
% с­ {1010}
% 
% р­ {1011}
% 
% о­ {1000}
% 
% ф­ {1001}
% }
% 
% \footnotesize
% \setlength{\parskip}{0.\parskip}
% \setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
% \setbeamertemplate{itemize/enumerate subbody begin}{\footnotesize}
% \setlength{\leftmargini}{0ex} 
% \medskip
% 
% $code(x)=
% 01101110000110010111010101111011100010010
% $
% 
% $|code(x)| = 5\cdot 1 + 2\cdot 3 + 5\cdot 4 + 2\cdot 5 = 41$ бит
% 
% \end{frame}


% \subsection{Фактическая длина данных при префиксном кодировании}
% \begin{frame}{\insertsubsection}
% \setlength{\leftmargini}{0ex} 
% \small
% \setlength{\parskip}{0.\parskip}
% 
% \begin{itemize}
% \item $code(x)=
% 01101110000110010111010101111011100010010
% $,
% $41$ бит
% 
% но записать в~файл можно только целое число байтов:
% %\mbox{(здесь "--- тетрад):}
% 
% % \hspace*{-3em}
% $%data(x)=
% 01101110000110010111010101111011100010010\textcolor{red}{000}
% $,
% \rlap{$44$ бита $= 11$ тетрад}
% 
% 
% \item 
% для декодирования нужно дерево/таблица кодов "---
% если алгоритм построения детерминирован, то %достаточно исходных частот:
% \termin{массив частот $\nu_i$:}
% для байта-тетрады "--- %массив 
% из 16 беззнаковых целых, для~байта-октета "--- 256;
% 
% 
% в~естественном порядке
% \begin{tabular}{@{}l@{}}
% \texttt{\color{gray}\textvisiblespace
%          ,.!?абвгикорстф}\\
% \texttt{0000050101111121}\\
% \color{gray}
% \texttt{0123456789ABCDEF}
% \end{tabular}.
% 
% % (32-битных? 64?)
% % Размер каждой частоты "--- как размер поля длины исходного файла $n$ (32 битa? 64?),
% % либо частоты нормируются: $\nu_i  \to \mathrm{round}\left( \frac{\nu_i}{\max_i(\nu_i)} \right).$
% 
% Размер $\nu_i$ "--- как размер поля $n$,
% либо перенормировка $\nu_i$.
% 
% 
% % \termin{Адаптивный (поточный) кодек} без массива частот: вначале считаем все символы равновероятными, и~код тождественен AVCII, после каждого записанного/прочитанного символа перестраиваем дерево.
% 
% \termin{Адаптивный (поточный) кодек:}  вначале считаем символы равновероятными (код=AVCII), после каждого записанного/прочитанного символа перестраиваем дерево.
% 
% % \end{itemize}
% % 
% % \end{frame}
% % \subsection{Фактическая длина данных (2)}
% % \begin{frame}{\insertsubsection}
% % \setlength{\leftmargini}{0ex} 
% % \small
% % 
% % Даже если для записи частоты используется один байт (норм.):
% % 
% % 16 тетрад массива частот (заголовок кодека) $+$ 11 тетрад данных $=$ 27 тетрад без основного заголовка архива.
% % 
% % Исходная длина $n=14$, то есть короткие файлы не имеет смысла сжимать.
% % 
% % \begin{itemize}
% 
% \item 
% Для определения того, каким конкретно декодером пользоваться "--- соответствующее поле заголовка (№ алгоритма сжатия без контекста).
% \end{itemize}
% \end{frame}


% \subsection{Адаптивный (поточный) кодек}
% \begin{frame}{\insertsubsection}
% 
% Вначале считаем символы равновероятными (код=значение байта как есть), после каждого записанного/прочитанного символа перестраиваем дерево:
% 
% \begin{itemize}
% \item собственно код $code(x)$ длиннее блочного кодека: 
% 
% оценка $|code(x)|$ снизу "--- не стационарный источник без памяти, а~нестационарный (набор вероятностей на каждом шаге меняется);
% 
% \item не требует для декодирования частот $(\nu_0, \nu_1, ..., \nu_N)$ $\implies$ общий размер файла может быть меньше, чем у~блочного.
% 
% \end{itemize}
% \end{frame}

% \begin{frame}{Оптимальность алгоритма Хаффмана}
% % Система кодов, полученная с помощью алгоритма Хаффмана "--- лучшая среди всех возможных систем префиксных кодов в том плане, что длина результирующей закодированной информационной последовательности получается минимальной. 
% % То есть алгоритм Хаффмана является оптимальным.
% Код Хаффмана имеет минимальную длину среди префиксных.
% 
% Не увеличивает размера исходных данных в~худшем случае.
% 
% % Основной недостаток алгоритма Хаффмана заключается в сложности процесса построения системы кодов. 
% % % Тем не менее именно оптимальный алгоритм Хаффмана является самым распространенным алгоритмом генерации кода переменной длины и находит свое воплощение в большинстве утилит сжатия и архивации информации.
% \end{frame}

% %  Коэффициенты компрессии: 8, 1,5, 1 (Лучший,
% % средний, худший коэффициенты).
% % ?
% %  Использование: Практически не применяется в чистом
% % виде. Обычно используется как один из этапов
% % компрессии в более сложных схемах.
% % ?
% %  Симметричность: 2 (за счет того, что требует двух
% % проходов по массиву сжимаемых данных).
% % ?
% %  Характерные особенности: Единственный алгоритм,
% % который не увеличивает размера исходных данных в
% % худшем случае (если не считать необходимости
% % хранить таблицу перекодировки вместе с файлом).

% \section{Арифметический (интервальный) код. Задачи для семинара}


\section{Арифметический (интервальный) код}
\subsection{Арифметический (интервальный) код}
\begin{frame}{\insertsubsection}
% \small

Неалфавитное неразделимое кодирование

$ C = c_0 c_1 c_2 ... c_n \to z  \in [0, 1); \hfill (0, 1)\isomorphism \Realset$

$I(z) \approx I(C)$, \hfill и~чаще всего  {$I(z) >> 64~\text{бит} > I(\mathlst{double})$}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}
% \frametitle{Литература}
% 
% \begin{itemize}
% \item Вентцель Е.\,С. Теория вероятностей: Учеб. для вузов. — 6-е изд. стер. — М.: Высш. шк., 1999.— 576 c. 
% 
% \item Пахомов\,С. Сравнение 64-битных архиваторов WinRAR 4.2, WinZip 17.0 и 7-Zip 9.30
% 
% \end{itemize}
% \end{frame}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

